{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NLP Sentiment Analysis for Earnings Calls\n",
        "\n",
        "This notebook demonstrates how to use transformer-based NLP models for analyzing earnings call transcripts and extracting trading signals.\n",
        "\n",
        "## Key Concepts\n",
        "- **FinBERT**: BERT model fine-tuned on financial text\n",
        "- **Sentiment Classification**: Positive, Negative, Neutral for financial statements\n",
        "- **Trading Signals**: Convert sentiment scores to actionable predictions\n",
        "\n",
        "## Requirements\n",
        "```bash\n",
        "pip install torch transformers numpy pandas matplotlib\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load FinBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained FinBERT model\n",
        "MODEL_NAME = \"ProsusAI/finbert\"\n",
        "\n",
        "print(\"Loading FinBERT model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded: {MODEL_NAME}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sample Earnings Call Statements\n",
        "\n",
        "We'll use synthetic examples representing typical earnings call language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample earnings call statements (synthetic examples)\n",
        "SAMPLE_STATEMENTS = [\n",
        "    # Positive statements\n",
        "    \"We are pleased to report record revenue growth of 25% year-over-year, driven by strong demand across all segments.\",\n",
        "    \"Our margins expanded significantly due to operational efficiencies and favorable product mix.\",\n",
        "    \"Customer acquisition exceeded expectations, with net new customers up 40% from last quarter.\",\n",
        "    \"We're raising our full-year guidance and expect continued momentum in the second half.\",\n",
        "    \"Free cash flow generation was exceptional, allowing us to accelerate our share buyback program.\",\n",
        "    \n",
        "    # Negative statements\n",
        "    \"We faced significant headwinds from supply chain disruptions that impacted our ability to meet demand.\",\n",
        "    \"Operating expenses increased substantially due to higher raw material costs and wage inflation.\",\n",
        "    \"Customer churn rates rose in the quarter, primarily in our enterprise segment.\",\n",
        "    \"We are lowering our guidance for the remainder of the year due to macroeconomic uncertainty.\",\n",
        "    \"Inventory write-downs negatively impacted our gross margin this quarter.\",\n",
        "    \n",
        "    # Neutral statements\n",
        "    \"Revenue came in line with our expectations at $2.5 billion for the quarter.\",\n",
        "    \"We continue to monitor the competitive landscape and adjust our strategy accordingly.\",\n",
        "    \"Our investment in R&D remains consistent with historical levels at approximately 15% of revenue.\",\n",
        "    \"We completed the previously announced acquisition and integration is proceeding as planned.\",\n",
        "    \"Our geographic mix shifted slightly with APAC representing 35% of total revenue.\"\n",
        "]\n",
        "\n",
        "# Expected labels for validation\n",
        "EXPECTED_LABELS = [\n",
        "    'positive', 'positive', 'positive', 'positive', 'positive',\n",
        "    'negative', 'negative', 'negative', 'negative', 'negative',\n",
        "    'neutral', 'neutral', 'neutral', 'neutral', 'neutral'\n",
        "]\n",
        "\n",
        "print(f\"Loaded {len(SAMPLE_STATEMENTS)} sample statements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sentiment Analysis Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_sentiment(texts, model, tokenizer, batch_size=8):\n",
        "    \"\"\"Analyze sentiment of financial texts using FinBERT\"\"\"\n",
        "    results = []\n",
        "    labels = ['positive', 'negative', 'neutral']\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            \n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                batch_texts, \n",
        "                padding=True, \n",
        "                truncation=True, \n",
        "                max_length=512,\n",
        "                return_tensors='pt'\n",
        "            ).to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            \n",
        "            # Get predictions\n",
        "            for j, text in enumerate(batch_texts):\n",
        "                prob_dict = {labels[k]: probs[j, k].item() for k in range(3)}\n",
        "                predicted_label = labels[probs[j].argmax().item()]\n",
        "                confidence = probs[j].max().item()\n",
        "                \n",
        "                # Composite sentiment score: positive - negative (range: -1 to 1)\n",
        "                sentiment_score = prob_dict['positive'] - prob_dict['negative']\n",
        "                \n",
        "                results.append({\n",
        "                    'text': text[:100] + '...' if len(text) > 100 else text,\n",
        "                    'label': predicted_label,\n",
        "                    'confidence': confidence,\n",
        "                    'sentiment_score': sentiment_score,\n",
        "                    'prob_positive': prob_dict['positive'],\n",
        "                    'prob_negative': prob_dict['negative'],\n",
        "                    'prob_neutral': prob_dict['neutral']\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Analyze all statements\n",
        "print(\"Analyzing sentiment...\")\n",
        "results_df = analyze_sentiment(SAMPLE_STATEMENTS, model, tokenizer)\n",
        "results_df['expected'] = EXPECTED_LABELS\n",
        "results_df['correct'] = results_df['label'] == results_df['expected']\n",
        "\n",
        "print(f\"\\nAccuracy: {results_df['correct'].mean():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display results table\n",
        "display_cols = ['text', 'label', 'expected', 'confidence', 'sentiment_score', 'correct']\n",
        "print(\"\\nSentiment Analysis Results:\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for idx, row in results_df.iterrows():\n",
        "    status = \"âœ“\" if row['correct'] else \"âœ—\"\n",
        "    score_bar = \"â–ˆ\" * int((row['sentiment_score'] + 1) * 10)\n",
        "    print(f\"\\n{idx+1}. {row['text'][:80]}...\")\n",
        "    print(f\"   Predicted: {row['label']:<10} Expected: {row['expected']:<10} {status}\")\n",
        "    print(f\"   Confidence: {row['confidence']:.2%}  Score: {row['sentiment_score']:+.3f}\")\n",
        "    print(f\"   [Neg]{'â”€'*10}[Neutral]{'â”€'*10}[Pos]\")\n",
        "    print(f\"         {score_bar}|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Sentiment Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Sentiment score distribution\n",
        "colors = {'positive': 'green', 'negative': 'red', 'neutral': 'gray'}\n",
        "for label in ['positive', 'negative', 'neutral']:\n",
        "    mask = results_df['expected'] == label\n",
        "    axes[0, 0].scatter(\n",
        "        results_df.loc[mask, 'sentiment_score'],\n",
        "        results_df.loc[mask, 'confidence'],\n",
        "        c=colors[label], label=label, s=100, alpha=0.7\n",
        "    )\n",
        "axes[0, 0].set_xlabel('Sentiment Score')\n",
        "axes[0, 0].set_ylabel('Confidence')\n",
        "axes[0, 0].set_title('Sentiment Score vs Confidence')\n",
        "axes[0, 0].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Probability distribution\n",
        "x = range(len(results_df))\n",
        "axes[0, 1].bar(x, results_df['prob_positive'], label='Positive', color='green', alpha=0.7)\n",
        "axes[0, 1].bar(x, results_df['prob_neutral'], bottom=results_df['prob_positive'], \n",
        "              label='Neutral', color='gray', alpha=0.7)\n",
        "axes[0, 1].bar(x, results_df['prob_negative'], \n",
        "              bottom=results_df['prob_positive'] + results_df['prob_neutral'],\n",
        "              label='Negative', color='red', alpha=0.7)\n",
        "axes[0, 1].set_xlabel('Statement Index')\n",
        "axes[0, 1].set_ylabel('Probability')\n",
        "axes[0, 1].set_title('Sentiment Probability Distribution')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(results_df['expected'], results_df['label'], \n",
        "                      labels=['positive', 'neutral', 'negative'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
        "           xticklabels=['Pos', 'Neu', 'Neg'],\n",
        "           yticklabels=['Pos', 'Neu', 'Neg'])\n",
        "axes[1, 0].set_xlabel('Predicted')\n",
        "axes[1, 0].set_ylabel('Actual')\n",
        "axes[1, 0].set_title('Confusion Matrix')\n",
        "\n",
        "# Sentiment score histogram\n",
        "axes[1, 1].hist(results_df['sentiment_score'], bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[1, 1].axvline(x=0, color='red', linestyle='--', label='Neutral')\n",
        "axes[1, 1].set_xlabel('Sentiment Score')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Sentiment Score Distribution')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Simulate Trading Signal Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_trading_signal(sentiment_score, confidence, threshold=0.3):\n",
        "    \"\"\"\n",
        "    Generate trading signal from sentiment analysis.\n",
        "    \n",
        "    Returns:\n",
        "        signal: 'BUY', 'SELL', or 'HOLD'\n",
        "        strength: Signal strength (0-1)\n",
        "    \"\"\"\n",
        "    # Confidence-weighted sentiment\n",
        "    weighted_score = sentiment_score * confidence\n",
        "    \n",
        "    if weighted_score > threshold:\n",
        "        return 'BUY', min(abs(weighted_score), 1.0)\n",
        "    elif weighted_score < -threshold:\n",
        "        return 'SELL', min(abs(weighted_score), 1.0)\n",
        "    else:\n",
        "        return 'HOLD', 0.0\n",
        "\n",
        "# Generate signals for all statements\n",
        "signals = []\n",
        "for _, row in results_df.iterrows():\n",
        "    signal, strength = generate_trading_signal(row['sentiment_score'], row['confidence'])\n",
        "    signals.append({'signal': signal, 'strength': strength})\n",
        "\n",
        "signals_df = pd.DataFrame(signals)\n",
        "results_df = pd.concat([results_df, signals_df], axis=1)\n",
        "\n",
        "# Display trading signals\n",
        "print(\"\\nTrading Signals:\")\n",
        "print(\"=\"*80)\n",
        "for idx, row in results_df.iterrows():\n",
        "    signal_icon = {'BUY': 'ðŸŸ¢', 'SELL': 'ðŸ”´', 'HOLD': 'âšª'}[row['signal']]\n",
        "    strength_bar = 'â–ˆ' * int(row['strength'] * 10)\n",
        "    print(f\"{idx+1}. {signal_icon} {row['signal']:<5} | Strength: {strength_bar:<10} ({row['strength']:.2f})\")\n",
        "    print(f\"   {row['text'][:60]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Simulate Earnings Call Analysis Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_earnings_call(paragraphs, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Analyze a full earnings call transcript.\n",
        "    \n",
        "    Args:\n",
        "        paragraphs: List of text paragraphs from earnings call\n",
        "        \n",
        "    Returns:\n",
        "        overall_sentiment: Aggregated sentiment score\n",
        "        section_results: DataFrame with per-section analysis\n",
        "    \"\"\"\n",
        "    # Analyze each paragraph\n",
        "    section_results = analyze_sentiment(paragraphs, model, tokenizer)\n",
        "    \n",
        "    # Aggregate sentiment (weighted by confidence)\n",
        "    weights = section_results['confidence']\n",
        "    overall_sentiment = np.average(section_results['sentiment_score'], weights=weights)\n",
        "    \n",
        "    # Key metrics\n",
        "    positive_ratio = (section_results['label'] == 'positive').mean()\n",
        "    negative_ratio = (section_results['label'] == 'negative').mean()\n",
        "    avg_confidence = section_results['confidence'].mean()\n",
        "    \n",
        "    return {\n",
        "        'overall_sentiment': overall_sentiment,\n",
        "        'positive_ratio': positive_ratio,\n",
        "        'negative_ratio': negative_ratio,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'section_results': section_results\n",
        "    }\n",
        "\n",
        "# Simulate analyzing multiple companies\n",
        "COMPANY_CALLS = {\n",
        "    'TechCorp': [\n",
        "        \"Revenue growth exceeded our expectations driven by cloud adoption.\",\n",
        "        \"We're seeing strong momentum in our AI products.\",\n",
        "        \"Customer retention improved significantly this quarter.\",\n",
        "        \"We're raising guidance for the full year.\"\n",
        "    ],\n",
        "    'RetailInc': [\n",
        "        \"Same-store sales declined due to reduced foot traffic.\",\n",
        "        \"Inventory levels remain elevated, requiring markdowns.\",\n",
        "        \"We're implementing cost reduction measures.\",\n",
        "        \"Consumer sentiment remains challenging.\"\n",
        "    ],\n",
        "    'BankCo': [\n",
        "        \"Net interest income was in line with expectations.\",\n",
        "        \"Credit quality remains stable across our portfolio.\",\n",
        "        \"We continue to invest in digital banking capabilities.\",\n",
        "        \"Capital ratios exceed regulatory requirements.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Analyzing Earnings Calls...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "company_signals = []\n",
        "for company, paragraphs in COMPANY_CALLS.items():\n",
        "    analysis = analyze_earnings_call(paragraphs, model, tokenizer)\n",
        "    signal, strength = generate_trading_signal(\n",
        "        analysis['overall_sentiment'], \n",
        "        analysis['avg_confidence']\n",
        "    )\n",
        "    \n",
        "    company_signals.append({\n",
        "        'company': company,\n",
        "        'sentiment': analysis['overall_sentiment'],\n",
        "        'confidence': analysis['avg_confidence'],\n",
        "        'positive_ratio': analysis['positive_ratio'],\n",
        "        'signal': signal,\n",
        "        'strength': strength\n",
        "    })\n",
        "    \n",
        "    signal_icon = {'BUY': 'ðŸŸ¢', 'SELL': 'ðŸ”´', 'HOLD': 'âšª'}[signal]\n",
        "    print(f\"\\n{company}:\")\n",
        "    print(f\"  Overall Sentiment: {analysis['overall_sentiment']:+.3f}\")\n",
        "    print(f\"  Positive Ratio: {analysis['positive_ratio']:.0%}\")\n",
        "    print(f\"  Confidence: {analysis['avg_confidence']:.2%}\")\n",
        "    print(f\"  Signal: {signal_icon} {signal} (strength: {strength:.2f})\")\n",
        "\n",
        "# Ranking\n",
        "signals_ranked = pd.DataFrame(company_signals).sort_values('sentiment', ascending=False)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nRanking by Sentiment:\")\n",
        "for i, (_, row) in enumerate(signals_ranked.iterrows(), 1):\n",
        "    print(f\"  {i}. {row['company']:<12} Sentiment: {row['sentiment']:+.3f} | Signal: {row['signal']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Attention Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_attention_weights(text, model, tokenizer):\n",
        "    \"\"\"Extract attention weights for visualization\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_attentions=True)\n",
        "    \n",
        "    # Get attention from last layer, average over heads\n",
        "    attention = outputs.attentions[-1][0].mean(dim=0)  # (seq_len, seq_len)\n",
        "    \n",
        "    # Get tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    \n",
        "    # Get CLS token attention (attention to other tokens)\n",
        "    cls_attention = attention[0, 1:-1].cpu().numpy()  # Skip [CLS] and [SEP]\n",
        "    tokens = tokens[1:-1]  # Skip special tokens\n",
        "    \n",
        "    return tokens, cls_attention\n",
        "\n",
        "# Visualize attention for a sample text\n",
        "sample_text = \"We are extremely pleased to report record revenue growth and raising our full-year guidance.\"\n",
        "\n",
        "tokens, attention = get_attention_weights(sample_text, model, tokenizer)\n",
        "\n",
        "# Normalize attention for visualization\n",
        "attention_norm = (attention - attention.min()) / (attention.max() - attention.min())\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "plt.bar(range(len(tokens)), attention_norm, color='steelblue')\n",
        "plt.xticks(range(len(tokens)), tokens, rotation=45, ha='right')\n",
        "plt.ylabel('Normalized Attention')\n",
        "plt.title(f'Attention Weights: \"{sample_text[:50]}...\"')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Highlight top attention tokens\n",
        "top_k = 5\n",
        "top_indices = np.argsort(attention)[-top_k:]\n",
        "print(f\"\\nTop {top_k} attended tokens:\")\n",
        "for idx in reversed(top_indices):\n",
        "    print(f\"  '{tokens[idx]}': {attention[idx]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **FinBERT**: Pre-trained transformer model for financial sentiment analysis\n",
        "2. **Sentiment Scoring**: Convert text to quantitative sentiment signals\n",
        "3. **Trading Signal Generation**: Threshold-based signal generation from sentiment\n",
        "4. **Earnings Call Analysis**: Aggregate paragraph-level sentiment for company scoring\n",
        "5. **Attention Visualization**: Understanding which words drive sentiment predictions\n",
        "\n",
        "### Key Insights:\n",
        "- FinBERT effectively classifies financial sentiment with high accuracy\n",
        "- Confidence-weighted aggregation improves signal quality\n",
        "- Key financial terms (revenue, growth, guidance) receive high attention weights\n",
        "\n",
        "### Extensions to Try:\n",
        "- Fine-tune FinBERT on your own labeled earnings call data\n",
        "- Combine with price data to measure predictive power\n",
        "- Add named entity recognition for ticker extraction\n",
        "- Implement real-time earnings call streaming analysis"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
